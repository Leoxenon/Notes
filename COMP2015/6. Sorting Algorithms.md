# Sorting Algorithms
- Internal sorting methods
	- all keys to be sorted are kept in main memory
	- The entire sort can be done in main memory
- External sorting methods
	- Sorts that cannot be performed in main memory and must be done on disk or tape are known as external sorting

- **Sorting algorithms**
	- **Linear sorting**
		- **Insertion Sort** 
			- Take the unsorted elements one at a time in sequence
			- Insert them into their appropriate location in the list
			- N - 1 times
			- Steps
				1. Initially p = 1
				2. Let the first p+1 elements be sorted
				3. Insert the (p+1)th element properly in the list so that now p+2 elements are sorted
				4. increment p
			- Best case
				- O(N)
			- Worst-case
				- O($N^2$)
			- advantage
				- relatively simple and easy to implement
			- disadvantage
				- not efficient to operate with a large list or input size
			- inversion
				- exactly the number of swaps that needed to be performed by insertion sort
				- Each swap between two adjacent elements removes exactly one inversion
				- On average, there are N(N-1)/4 inversions in an array of N distinct elements
		- **Shell Sort**
			- Sort many smaller sub-arrays using insertion sort before sorting the entire array
			- diminishing increment sort
				- In each step, sample every item spaced hk apart and form a sub-array. Then sort the sub-arrays
					- $A[0], A[h_k], A[2h_k], A[3h_k], …$
					- $A[1], A[h_k+1], A[2h_k +1], A[3h_k +1], …$
					- $…$
					- $A[h_k-1], A[2h_k-1], A[3h_k-1], A[4h_k-1], …$
				- After these sub-arrays are sorted, choose a new, smaller value for hk, and sort the new sub-arrays
				- Finally, sort with hk = 1.
	- **HeapSort** 
		- build a binary heap of N elements
		- perform N - 1 DeleteMin operations
		- record these elements
		- Heapsort: no extra storage
			- After each deleteMin, the size of heap shrinks by 1
				- use the last cell just freed up to store the element that was just deleted
			- to sort in descending order
				- min heap
			- to sort in ascending order
				- max heap
	- **Divide & Conquer sorting**
		- **MergeSort**
			- breaks the data into small data sets
			- sorts those small sets
			- merges the resulting sorted lists together
			- Steps
				- Divide the list into two smaller lists of about equal sizes
					- O(1)
				- sort each smaller list recursively
					- 2 T(N/2)
				- merge the two sorted lists to get one sorted list
					- O(m1 + m2)
			- $T(N) = 2 T(N/2) + N$
				$\frac{T(N)}{N} = \frac{T(N/2)}{N/2} + 1$
				$\frac{T(N)}{N} = \frac{T(1)}{1} + logN$
				$T(N) = N + NlogN$
				$T(N)= O(NlogN)$
			- $T(N) = 2 T(\frac{N}{2}) + N$
				$= 2(2T(\frac{N}{4}) + \frac{N}{2}) + N$
				$= 2^k T(\frac{N}{2^k}) + kN$
				$= N + NlogN$
				$= O(NlogN)$
			- Main problem
				- Merging requires extra memory and additional work of copying to the temporary array and back
			- Used for external sorting
				- hardly used for main memory sorts
		- **Quick Sort**
			- Fastest known sorting algorithm in practice
			- Steps
				- Divide step
					- Pick any element (pivot) v in list S
						1. Use the first element as pivot
							- if random, fine
							- if presorted
								- $O(N^2)$
								- poor choice
						2. Choose the pivot randomly
							- generally safe
							- random number generation can be expensive
						3. Use the median of three
							- pick the median of the first, center and last element
							- an optimal quicksort
								- $O(NlogN)$
							- hard to find the exact median
					- Partition S - {v} into two disjoint groups
						- The left group S1 consists of elements that are smaller than the pivot
						- The right group S2 consists of elements that are larger than the pivot
						- Partitioning Strategy
							1. Swap the pivot element with the last element
							2. Set i to the first element and j to the next-to-last element
							3. Move i to the right until it refers to an element that is larger than the pivot
							4. Move j to the left until it refers to an element that is smaller than the pivot
							5. If i is to the left of j, swap the elements at positions i and j
							6. Continue the process until i and j meet or i surpasses j
							7. Swap the pivot element and the element at position i
						- when some elements are equal to the pivot
							- It is better to stop i and/or j (for swapping)
				- Conquer step
					- recursively sort S1 and S2
				- Combine step
					- combine the sorted S1
					- followed by v
					- followed by the sorted S2
			- For very small arrays, quicksort does not perform as well as insertion sort
				- A good cutoff is about 10
			- Analysis of Quicksort
				- Assumptions
					- A random pivot
					- No cutoff for small arrays
				- Running time
					- pivot selection
						- O(1)
					- partitioning
						- O(N)
					- running time of two recursive calls
				- $T(N) = T(i) + T(N - i - 1) + cN$
					- Worst-Case Analysis
						- $T(N) = T(N– 1) + cN$
						- $T(N– 1) = T(N–2) + c(N–1)$
						- $T(N– 2) = T(N–3) + c(N–2)$
						- $. . .$
						- $T(2) = T(1) + c(2)$
						- $T(N) = T(1) + c∑i = O(N^2)$
					- Best-Case Analysis
						- $T(N) = 2 T(N/2) + cN$
						- $\frac{T(N)}{N} = \frac{T(N/2)}{N/2} + c$
						- $\frac{T(N)}{N} = \frac{T(1)}{1} + clogN$
						- $T(N) = N + cNlogN$
						- $T(N)= O(NlogN)$
					- Average-Case Analysis
						- $T(N) = T(i) + T(N - i - 1) + cN$
						- the probability of the case of i is 1/N
						- $T(N) = \frac{1}{N}∑T(i) + \frac{1}{N}∑T(N-i-1) + cN$
						- $T(N) = \frac{2}{N}∑T(j) + cN$
						- $NT(N) = 2∑T(j) + cN^2$
						- $(N - 1)T(N - 1) = 2∑T(j) + c(N - 1)^2$
						- $NT(N) - (N - 1)T(N - 1) = 2T(N - 1) + c[N^2 - (N - 1)^2]$
						- $NT(N) = (N+1)T(N - 1) + 2cN$ 
						- $\frac{T(N)}{N+1} = \frac{T(N - 1)}{N} + \frac{2c}{N+1}$
						- $\frac{T(N - 1)}{N} = \frac{T(N - 2)}{N-1} + \frac{2c}{N}$
						- $...$
						- $\frac{T(2)}{3} = \frac{T(1)}{2} + \frac{2c}{3}$
						- $\frac{T(1)}{2} = \frac{1}{2}$
						- $\frac{T(N)}{N+1} = \frac{1}{2} + 2c∑\frac{1}{i} = O(logN)$
						- $T(N) = O(NlogN)$
	- **Bucket Sort**
		- external sorting

```cpp
void InsertionSort(ElementType A[], int N) { 
	int j, P;
	Element Type Tmp;
	for (P=1; P < N; P++) {
		Tmp = A[P];
		for (j = P; j > 0 && A[j-1]>Tmp; j--) 
			A[j] = A[j-1]; 
		A[j] = Tmp; 
	} 
}
```

```cpp
/* using increments of N/2, N/4, ..., 1, suggested by Shell */ 
void Shellsort (ElementType A [ ], int N) { 
	int i, j, Increment; 
	ElementType Tmp; 
	for (Increment = N / 2; Increment > 0; Increment /= 2 ) 
		for (i = Increment; i < N; i++ ) { 
			Tmp = A [i]; 
			for (j = i; j >= Increment; j -= Increment) 
				if (Tmp < A [j - Increment]) 
					A [j] = A [j - Increment]; 
				else
					break;
				A [j] = Tmp; 
		} 
}
```

## **Tutorial**
![[COMP2015/6.png/Tutorial 1.png]]
- Almost sorted
	- Insertion sort is about O(N)

![[COMP2015/6.png/Tutorial 2.png]]
- Internal sorting
	- Heap sort
	- Quick sort

![[COMP2015/6.png/Tutorial 3.png]]
$a_1 < a_2 < a_3 <  ... < a_n$ , Add $b_1, b_2$
- $a_n < b_1 < b_2$
	- best case, no inversion
- $a_n > b_1 > b_2$
	- worst case, (N + 1) + N inversions
- In total
	- 2N + 1 possible number of inversions

![[COMP2015/6.png/Tutorial 4.png]]
```cpp
V findSecSmallest(V[] heap) {
	return heap[2] < heap[3] || heap[3] == null ? heap[2] : heap[3]
}
```

![[COMP2015/6.png/Tutorial 5.png]]
- 5 elements
	- if second smallest is heap[2]
		- compare heap[3], heap[4], heap[5]
	- if second smallest is heap[3]
		- compare heap[2], heap[6], heap[7]
